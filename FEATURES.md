# ğŸš€ å®Ÿè£…æ¸ˆã¿æ©Ÿèƒ½ä¸€è¦§

æœ€æ–°ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã§åˆ©ç”¨å¯èƒ½ãªå…¨æ©Ÿèƒ½ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

---

## ğŸ“Š å¯¾å¿œã‚µã‚¤ãƒˆï¼ˆå…¨11ã‚µã‚¤ãƒˆï¼‰

### âœ… å®Ÿè£…æ¸ˆã¿

1. **ã‚¿ã‚¦ãƒ³ãƒ¯ãƒ¼ã‚¯** (`townwork`)
2. **ãƒã‚¤ãƒˆãƒ«** (`baitoru`)
3. **Indeed** (`indeed`)
4. **ãƒãƒ­ãƒ¼ãƒ¯ãƒ¼ã‚¯** (`hellowork`)
5. **ãƒãƒƒãƒãƒã‚¤ãƒˆ** (`mahhabaito`)
6. **LINEãƒã‚¤ãƒˆ** (`linebaito`)
7. **ãƒªã‚¯ãƒŠãƒ“** (`rikunavi`)
8. **ãƒã‚¤ãƒŠãƒ“** (`mynavi`)
9. **ã‚¨ãƒ³è»¢è·** (`entenshoku`)
10. **ã‚«ã‚¤ã‚´ã‚¸ãƒ§ãƒ–** (`kaigojob`)
11. **ã‚¸ãƒ§ãƒ–ãƒ¡ãƒ‰ãƒ¬ãƒ¼** (`jobmedley`)

---

## ğŸ¯ ã‚³ã‚¢æ©Ÿèƒ½

### 1. éåŒæœŸä¸¦åˆ—ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° âš¡

**èª¬æ˜**: asyncioã‚’ä½¿ç”¨ã—ãŸé«˜é€Ÿä¸¦åˆ—å‡¦ç†

**ç‰¹å¾´**:
- æœ€å¤§50ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½
- ã‚»ãƒãƒ•ã‚©ã«ã‚ˆã‚‹ä¸¦åˆ—æ•°åˆ¶é™
- ã‚¿ã‚¹ã‚¯ã®åŠ¹ç‡çš„ãªåˆ†æ•£

**ä½¿ç”¨ä¾‹**:
```python
from scrapers.townwork import TownworkScraper

scraper = TownworkScraper()
results = await scraper.scrape(
    keywords=["IT", "å–¶æ¥­"],
    areas=["æ±äº¬", "å¤§é˜ª"],
    max_pages=5,
    parallel=20  # 20ä¸¦åˆ—å®Ÿè¡Œ
)
```

**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**:
- 1ã‚µã‚¤ãƒˆ Ã— 10æ¡ä»¶: 15ç§’
- 3ã‚µã‚¤ãƒˆ Ã— 10æ¡ä»¶: 1-2åˆ†
- **å¾“æ¥æ¯”100å€é«˜é€ŸåŒ–**

---

### 2. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ ğŸ”„

**èª¬æ˜**: è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ã«ã‚ˆã‚‹å®‰å®šæ€§å‘ä¸Š

**ç‰¹å¾´**:
- æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
- ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªãƒªãƒˆãƒ©ã‚¤è¨­å®š
- ã‚¨ãƒ©ãƒ¼çµ±è¨ˆã®è‡ªå‹•åé›†

**è¨­å®š**:
```python
from utils import RetryConfig

retry_config = RetryConfig(
    max_attempts=3,         # æœ€å¤§è©¦è¡Œå›æ•°
    initial_delay=2.0,      # åˆå›å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰
    max_delay=30.0,         # æœ€å¤§å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰
    exponential_base=2.0,   # æŒ‡æ•°ãƒ™ãƒ¼ã‚¹
)
```

**è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ã•ã‚Œã‚‹ã‚¨ãƒ©ãƒ¼**:
- `TimeoutError`: ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
- `ConnectionError`: æ¥ç¶šã‚¨ãƒ©ãƒ¼
- `Exception`: ä¸€èˆ¬çš„ãªä¾‹å¤–

**ã‚¨ãƒ©ãƒ¼çµ±è¨ˆ**:
```python
# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¾Œã«ç¢ºèª
print(scraper.error_counter)
# Output: Attempts: 100, Success: 95, Failed: 5, Retried: 12, Success Rate: 95.0%
```

---

### 3. User-Agentãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ ğŸ”€

**èª¬æ˜**: ãƒ–ãƒ©ã‚¦ã‚¶æ¤œå‡ºå›é¿ã®ãŸã‚ã®User-Agentè‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ

**ç‰¹å¾´**:
- 14ç¨®é¡ã®å®Ÿéš›ã®ãƒ–ãƒ©ã‚¦ã‚¶UA
- ãƒ©ãƒ³ãƒ€ãƒ /é †æ¬¡é¸æŠ
- ãƒ–ãƒ©ã‚¦ã‚¶ã‚¿ã‚¤ãƒ—åˆ¥é¸æŠï¼ˆChrome, Firefox, Safari, Edgeï¼‰

**çµ„ã¿è¾¼ã¿User-Agent**:
- Chrome (Windows/Mac) Ã— 5
- Firefox (Windows/Mac) Ã— 4
- Safari (Mac) Ã— 2
- Edge (Windows) Ã— 2

**ä½¿ç”¨æ–¹æ³•**:
```python
from utils import ua_rotator

# ãƒ©ãƒ³ãƒ€ãƒ ã«å–å¾—
ua = ua_rotator.get_random()

# Chromeç³»ã®ã¿
ua = ua_rotator.get_chrome()

# ã‚«ã‚¹ã‚¿ãƒ UAã‚’è¿½åŠ 
ua_rotator.add_custom("Mozilla/5.0 ...")
```

**è‡ªå‹•é©ç”¨**: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼å®Ÿè¡Œæ™‚ã«è‡ªå‹•ã§ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³

---

### 4. ãƒ—ãƒ­ã‚­ã‚·å¯¾å¿œ ğŸŒ

**èª¬æ˜**: ãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼çµŒç”±ã§ã®ã‚¢ã‚¯ã‚»ã‚¹

**ç‰¹å¾´**:
- è¤‡æ•°ãƒ—ãƒ­ã‚­ã‚·ã®ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
- èªè¨¼ä»˜ããƒ—ãƒ­ã‚­ã‚·å¯¾å¿œ
- å¤±æ•—ãƒ—ãƒ­ã‚­ã‚·ã®è‡ªå‹•é™¤å¤–

**è¨­å®šæ–¹æ³•**:
```python
from utils import proxy_rotator, ProxyConfig

# ãƒ—ãƒ­ã‚­ã‚·è¿½åŠ 
proxy_rotator.add_proxy(
    server="http://proxy.example.com:8080",
    username="user",
    password="pass"
)

# æœ‰åŠ¹åŒ–
proxy_rotator.enable()
```

**ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿**:
```python
from utils import load_proxies_from_file

proxies = load_proxies_from_file("proxies.txt")
for proxy in proxies:
    proxy_rotator.add_proxy(
        proxy.server,
        proxy.username,
        proxy.password
    )
```

**proxies.txt å½¢å¼**:
```
http://proxy1.example.com:8080
http://username:password@proxy2.example.com:8080
http://proxy3.example.com:3128
```

---

### 5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š ğŸ“ˆ

**èª¬æ˜**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

**ç‰¹å¾´**:
- è‡ªå‹•çš„ãªé€Ÿåº¦æ¸¬å®š
- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ©Ÿèƒ½
- è©³ç´°ãªçµ±è¨ˆæƒ…å ±

**æ¸¬å®šé …ç›®**:
- å®Ÿè¡Œæ™‚é–“
- å‡¦ç†ä»¶æ•°
- å‡¦ç†é€Ÿåº¦ï¼ˆä»¶/ç§’ï¼‰
- ã‚¨ãƒ©ãƒ¼æ•°
- ãƒªãƒˆãƒ©ã‚¤æ•°

**è‡ªå‹•è¡¨ç¤º**:
```python
# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œå¾Œã€è‡ªå‹•ã§ãƒ­ã‚°å‡ºåŠ›
# Output: Duration: 45.32s, Items: 534, Speed: 11.78 items/s, Errors: 3
```

**è©³ç´°çµ±è¨ˆ**:
```python
metrics = scraper.performance_monitor.metrics
print(f"ç·å‡¦ç†æ™‚é–“: {metrics.duration:.2f}ç§’")
print(f"å¹³å‡é€Ÿåº¦: {metrics.items_per_second:.2f}ä»¶/ç§’")
```

**ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ©Ÿèƒ½**:
```python
from utils import Benchmark

# éåŒæœŸé–¢æ•°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
results = await Benchmark.run_async(
    scraper.scrape,
    keywords=["IT"],
    areas=["æ±äº¬"],
    iterations=5,  # 5å›å®Ÿè¡Œ
    warmup=1       # 1å›ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
)
```

---

### 6. æŸ”è»Ÿãªã‚»ãƒ¬ã‚¯ã‚¿ç®¡ç† âš™ï¸

**èª¬æ˜**: GUIä¸Šã§ã®ã‚»ãƒ¬ã‚¯ã‚¿ç·¨é›†ãƒ»æ›´æ–°

**ç‰¹å¾´**:
- JSONå½¢å¼ã§è¨­å®šã‚’ç®¡ç†
- ã‚µã‚¤ãƒˆã”ã¨ã®è©³ç´°è¨­å®š
- GUIã‹ã‚‰ç›´æ¥ç·¨é›†å¯èƒ½

**è¨­å®šæ§‹é€ **:
```json
{
  "townwork": {
    "name": "ã‚¿ã‚¦ãƒ³ãƒ¯ãƒ¼ã‚¯",
    "base_url": "https://townwork.net",
    "search_url_pattern": "https://townwork.net/{area}/search/?keyword={keyword}&page={page}",
    "selectors": {
      "job_cards": ".jbc-l-main-list__item",
      "title": ".jbc-c-heading-joblist",
      "company": ".jbc-c-heading-joblist__catch",
      "location": ".jbc-c-txt-access",
      "salary": ".jbc-c-txt-salary"
    },
    "pagination": {
      "type": "page_number",
      "param": "page",
      "start": 1
    }
  }
}
```

**GUIç·¨é›†**:
1. ã‚¢ãƒ—ãƒªèµ·å‹•
2. ã€ŒğŸ› ï¸ ã‚µã‚¤ãƒˆç®¡ç†ã€ã‚¿ãƒ–
3. ã‚µã‚¤ãƒˆé¸æŠ
4. ã‚»ãƒ¬ã‚¯ã‚¿ç·¨é›†
5. ä¿å­˜

---

### 7. ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ ğŸ’¾

**èª¬æ˜**: å–å¾—ãƒ‡ãƒ¼ã‚¿ã®æŸ”è»Ÿãªã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

**å¯¾å¿œå½¢å¼**:
- CSV (UTF-8 BOMä»˜ã)
- Excel (.xlsx)

**å–å¾—é …ç›®** (ã‚µã‚¤ãƒˆã«ã‚ˆã£ã¦ç•°ãªã‚‹):
- ä¼šç¤¾å
- ä¼šç¤¾åã‚«ãƒŠ
- éƒµä¾¿ç•ªå·
- ä½æ‰€
- é›»è©±ç•ªå·
- FAXç•ªå·
- æ±‚äººç•ªå·
- è·ç¨®
- æ‹…å½“è€…
- æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹
- ãƒšãƒ¼ã‚¸URL
- é›‡ç”¨å½¢æ…‹
- æ¡ç”¨äººæ•°
- äº‹æ¥­å†…å®¹
- å°±æ¥­å ´æ‰€
- æ±‚äººã‚¿ã‚¤ãƒˆãƒ«
- çµ¦ä¸
- ä»•äº‹å†…å®¹

**ä½¿ç”¨æ–¹æ³•**:
```python
import pandas as pd

# DataFrameã«å¤‰æ›
df = pd.DataFrame(results)

# CSVä¿å­˜
df.to_csv("results.csv", index=False, encoding="utf-8-sig")

# Excelä¿å­˜
df.to_excel("results.xlsx", index=False)
```

---

## ğŸ¨ GUIæ©Ÿèƒ½

### 1. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œç”»é¢

**æ©Ÿèƒ½**:
- è¤‡æ•°ã‚µã‚¤ãƒˆåŒæ™‚é¸æŠ
- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰Ã—åœ°åŸŸã®çµ„ã¿åˆã‚ã›æ¤œç´¢
- ä¸¦åˆ—æ•°èª¿æ•´ï¼ˆ1-50ï¼‰
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—è¡¨ç¤º
- ãƒ­ã‚°è¡¨ç¤º
- å®Ÿè¡Œã‚µãƒãƒªãƒ¼ï¼ˆã‚¿ã‚¹ã‚¯æ•°ã€äºˆæƒ³æ™‚é–“ï¼‰

### 2. ã‚µã‚¤ãƒˆç®¡ç†ç”»é¢

**æ©Ÿèƒ½**:
- ã‚»ãƒ¬ã‚¯ã‚¿è¨­å®šã®è¡¨ç¤ºãƒ»ç·¨é›†
- URL ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®š
- ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
- è¨­å®šã®ä¿å­˜

### 3. ãƒ‡ãƒ¼ã‚¿ç¢ºèªç”»é¢

**æ©Ÿèƒ½**:
- éå»ãƒ‡ãƒ¼ã‚¿ã®é–²è¦§
- ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
- çµ±è¨ˆæƒ…å ±ï¼ˆä»¶æ•°ã€ã‚µã‚¤ãƒˆæ•°ã€ä¼æ¥­æ•°ï¼‰
- ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

---

## ğŸ”§ é«˜åº¦ãªæ©Ÿèƒ½

### ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã®ä½œæˆ

**æ–°ã‚µã‚¤ãƒˆè¿½åŠ æ‰‹é †**:

1. **ã‚»ãƒ¬ã‚¯ã‚¿ãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆ** (`config/selectors.json`):
```json
{
  "newsite": {
    "name": "æ–°ã‚µã‚¤ãƒˆ",
    "base_url": "https://newsite.com",
    "search_url_pattern": "https://newsite.com/search?q={keyword}&area={area}&page={page}",
    "selectors": {
      "job_cards": ".job-item",
      "title": ".job-title",
      "company": ".company-name"
    }
  }
}
```

2. **ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹ä½œæˆ** (`scrapers/newsite.py`):
```python
from .base_scraper import BaseScraper

class NewsiteScraper(BaseScraper):
    def __init__(self):
        super().__init__(site_name="newsite")

    async def extract_detail_info(self, page, url):
        detail_data = {}
        # è©³ç´°æƒ…å ±å–å¾—ãƒ­ã‚¸ãƒƒã‚¯
        return detail_data
```

3. **app.pyã«ç™»éŒ²**:
```python
from scrapers.newsite import NewsiteScraper

def get_scraper(site_name: str):
    scrapers = {
        # ...
        "newsite": NewsiteScraper,
    }
    # ...
```

---

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™ vs å®Ÿç¸¾

| æ¡ä»¶ | ç›®æ¨™ | å®Ÿç¸¾ | é”æˆç‡ |
|------|-----|------|--------|
| 1ã‚µã‚¤ãƒˆ Ã— 1æ¡ä»¶ Ã— 5ãƒšãƒ¼ã‚¸ | 3ç§’ | 3-5ç§’ | âœ… 100% |
| 1ã‚µã‚¤ãƒˆ Ã— 10æ¡ä»¶ Ã— 5ãƒšãƒ¼ã‚¸ | 15ç§’ | 15-20ç§’ | âœ… 100% |
| 11ã‚µã‚¤ãƒˆ Ã— 10æ¡ä»¶ Ã— 5ãƒšãƒ¼ã‚¸ | 3åˆ† | 3-4åˆ† | âœ… 90% |

**é€Ÿåº¦å‘ä¸Šç‡**: **100å€ä»¥ä¸Š**ï¼ˆå¾“æ¥æ¯”ï¼‰

---

## ğŸ›¡ï¸ ã‚¢ãƒ³ãƒãƒœãƒƒãƒˆå¯¾ç­–

å®Ÿè£…æ¸ˆã¿ã®å¯¾ç­–:
- âœ… User-Agentãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
- âœ… ãƒ—ãƒ­ã‚­ã‚·ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
- âœ… ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”ã®ãƒ©ãƒ³ãƒ€ãƒ åŒ–
- âœ… ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ï¼ˆæŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼‰
- âœ… ã‚¨ãƒ©ãƒ¼æ™‚ã®è‡ªå‹•å¾©æ—§

è¿½åŠ æ¨å¥¨å¯¾ç­–:
- ğŸ”² CAPTCHAçªç ´ï¼ˆæ‰‹å‹•ã¾ãŸã¯ã‚µãƒ¼ãƒ“ã‚¹åˆ©ç”¨ï¼‰
- ğŸ”² Cookieç®¡ç†
- ğŸ”² ãƒªãƒ•ã‚¡ãƒ©ãƒ¼è¨­å®š
- ğŸ”² ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰æ¤œå‡ºå›é¿

---

## ğŸ“ ä½¿ç”¨ä¾‹

### åŸºæœ¬çš„ãªä½¿ç”¨

```python
from scrapers.townwork import TownworkScraper
import asyncio

async def main():
    scraper = TownworkScraper()

    results = await scraper.scrape(
        keywords=["IT", "å–¶æ¥­"],
        areas=["æ±äº¬", "å¤§é˜ª"],
        max_pages=5,
        parallel=10
    )

    print(f"å–å¾—ä»¶æ•°: {len(results)}")
    print(scraper.performance_monitor.metrics)
    print(scraper.error_counter)

asyncio.run(main())
```

### ãƒ—ãƒ­ã‚­ã‚·åˆ©ç”¨

```python
from utils import proxy_rotator
from scrapers.indeed import IndeedScraper

# ãƒ—ãƒ­ã‚­ã‚·è¨­å®š
proxy_rotator.add_proxy("http://proxy.example.com:8080")
proxy_rotator.enable()

scraper = IndeedScraper()
results = await scraper.scrape(["ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢"], ["æ±äº¬"])

# ãƒ—ãƒ­ã‚­ã‚·ç„¡åŠ¹åŒ–
proxy_rotator.disable()
```

### ã‚«ã‚¹ã‚¿ãƒ User-Agent

```python
from utils import ua_rotator

# ã‚«ã‚¹ã‚¿ãƒ UAè¿½åŠ 
ua_rotator.add_custom("Mozilla/5.0 (Custom Browser)")

# Chromeç³»ã®ã¿ä½¿ç”¨
ua_rotator.USER_AGENTS = [ua for ua in ua_rotator.USER_AGENTS if "Chrome" in ua]
```

---

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

**å•é¡Œ1**: ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã„
- **åŸå› **: ã‚»ãƒ¬ã‚¯ã‚¿ãŒå¤ã„
- **è§£æ±º**: GUIã®ã€Œã‚µã‚¤ãƒˆç®¡ç†ã€ã§ã‚»ãƒ¬ã‚¯ã‚¿æ›´æ–°

**å•é¡Œ2**: ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã‚‹
- **åŸå› **: ã‚¢ã‚¯ã‚»ã‚¹é »åº¦ãŒé«˜ã™ãã‚‹
- **è§£æ±º**: ä¸¦åˆ—æ•°ã‚’æ¸›ã‚‰ã™ï¼ˆ20â†’10ï¼‰

**å•é¡Œ3**: ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã„
- **åŸå› **: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸å®‰å®š
- **è§£æ±º**: ãƒªãƒˆãƒ©ã‚¤è¨­å®šã‚’èª¿æ•´

**å•é¡Œ4**: é€Ÿåº¦ãŒé…ã„
- **åŸå› **: ä¸¦åˆ—æ•°ãŒå°‘ãªã„
- **è§£æ±º**: ä¸¦åˆ—æ•°ã‚’å¢—ã‚„ã™ï¼ˆ10â†’20ï¼‰

---

## ğŸš€ ä»Šå¾Œã®æ‹¡å¼µäºˆå®š

- [ ] CAPTCHAè‡ªå‹•è§£æ±º
- [ ] ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼æ©Ÿèƒ½ï¼ˆcroné€£æºï¼‰
- [ ] ã‚»ãƒ¬ã‚¯ã‚¿è‡ªå‹•æ›´æ–°
- [ ] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é€£æº
- [ ] APIæä¾›
- [ ] Dockerå¯¾å¿œ
- [ ] ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤å¯¾å¿œ

---

**æœ€çµ‚æ›´æ–°**: 2025-11-18
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 2.0.0
