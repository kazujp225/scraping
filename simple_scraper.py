"""
ã‚·ãƒ³ãƒ—ãƒ«ã§ç¢ºå®Ÿã«å‹•ãã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼
1ãƒ•ã‚¡ã‚¤ãƒ«å®Œçµãƒ»ã™ãã«å®Ÿè¡Œå¯èƒ½
"""
import asyncio
from playwright.async_api import async_playwright
import json
from datetime import datetime


async def scrape_indeed_simple():
    """
    Indeedã‹ã‚‰æ±‚äººæƒ…å ±ã‚’å–å¾—
    ã‚·ãƒ³ãƒ—ãƒ«ã§ç¢ºå®Ÿã«å‹•ãå®Ÿè£…
    """
    print("\n" + "="*60)
    print("æ±‚äººã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° - ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ")
    print("="*60 + "\n")

    # æ¤œç´¢æ¡ä»¶
    keyword = "ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼"
    location = "æ±äº¬"

    print(f"æ¤œç´¢æ¡ä»¶: {keyword} in {location}")
    print("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’èµ·å‹•ä¸­...\n")

    async with async_playwright() as p:
        # ãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•ï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ï¼‰
        browser = await p.chromium.launch(
            headless=False,  # ãƒ–ãƒ©ã‚¦ã‚¶ã‚’è¡¨ç¤ºï¼ˆå‹•ä½œç¢ºèªç”¨ï¼‰
            args=[
                "--disable-blink-features=AutomationControlled",
                "--no-sandbox"
            ]
        )

        # ãƒšãƒ¼ã‚¸ä½œæˆ
        context = await browser.new_context(
            viewport={"width": 1920, "height": 1080},
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
        page = await context.new_page()

        try:
            # Indeedæ¤œç´¢ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            url = f"https://jp.indeed.com/jobs?q={keyword}&l={location}"
            print(f"ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {url}")

            await page.goto(url, wait_until="domcontentloaded", timeout=30000)
            print("âœ… ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å®Œäº†\n")

            # å°‘ã—å¾…æ©Ÿ
            await asyncio.sleep(3)

            # æ±‚äººã‚«ãƒ¼ãƒ‰ã‚’å–å¾—ï¼ˆè¤‡æ•°ã®ã‚»ãƒ¬ã‚¯ã‚¿ã‚’è©¦ã™ï¼‰
            selectors_to_try = [
                ".job_seen_beacon",
                ".jobsearch-SerpJobCard",
                "div[data-jk]",
                ".slider_item",
                "td.resultContent"
            ]

            job_cards = []
            used_selector = None

            for selector in selectors_to_try:
                job_cards = await page.query_selector_all(selector)
                if len(job_cards) > 0:
                    used_selector = selector
                    print(f"âœ… ã‚»ãƒ¬ã‚¯ã‚¿ '{selector}' ã§ {len(job_cards)} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\n")
                    break
                else:
                    print(f"â­ï¸  ã‚»ãƒ¬ã‚¯ã‚¿ '{selector}' ã§ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

            if not job_cards:
                print("\nâŒ æ±‚äººã‚«ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                print("ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã™...")
                await page.screenshot(path="error_screenshot.png", full_page=True)
                print("ä¿å­˜å®Œäº†: error_screenshot.png")
                return []

            print(f"ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚’é–‹å§‹ã—ã¾ã™...\n")

            # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            jobs = []
            for i, card in enumerate(job_cards[:10], 1):  # æœ€åˆã®10ä»¶ã®ã¿
                try:
                    # ã‚¿ã‚¤ãƒˆãƒ«å–å¾—ï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™ï¼‰
                    title = None
                    title_selectors = ["h2.jobTitle", ".jobTitle", "h2 a", ".jcs-JobTitle"]
                    for ts in title_selectors:
                        elem = await card.query_selector(ts)
                        if elem:
                            title = await elem.inner_text()
                            break

                    # ä¼šç¤¾åå–å¾—
                    company = None
                    company_selectors = [".companyName", "[data-testid='company-name']", ".company"]
                    for cs in company_selectors:
                        elem = await card.query_selector(cs)
                        if elem:
                            company = await elem.inner_text()
                            break

                    # å ´æ‰€å–å¾—
                    location_elem = await card.query_selector(".companyLocation")
                    location_text = await location_elem.inner_text() if location_elem else "N/A"

                    # çµ¦ä¸å–å¾—
                    salary_elem = await card.query_selector(".salary-snippet")
                    salary = await salary_elem.inner_text() if salary_elem else "N/A"

                    if title:  # ã‚¿ã‚¤ãƒˆãƒ«ãŒã‚ã‚Œã°è¿½åŠ 
                        job = {
                            "ç•ªå·": i,
                            "ã‚¿ã‚¤ãƒˆãƒ«": title.strip() if title else "N/A",
                            "ä¼šç¤¾å": company.strip() if company else "N/A",
                            "å ´æ‰€": location_text.strip(),
                            "çµ¦ä¸": salary.strip()
                        }
                        jobs.append(job)
                        print(f"{i}. {job['ã‚¿ã‚¤ãƒˆãƒ«'][:40]}... - {job['ä¼šç¤¾å'][:30]}")

                except Exception as e:
                    print(f"âš ï¸  ã‚«ãƒ¼ãƒ‰ {i} ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼: {e}")
                    continue

            print(f"\nâœ… åˆè¨ˆ {len(jobs)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")

            # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"indeed_jobs_{timestamp}.json"

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(jobs, f, ensure_ascii=False, indent=2)

            print(f"\nğŸ’¾ çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")

            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜
            screenshot_file = f"screenshot_{timestamp}.png"
            await page.screenshot(path=screenshot_file, full_page=True)
            print(f"ğŸ“¸ ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜: {screenshot_file}")

            return jobs

        except Exception as e:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜
            try:
                await page.screenshot(path="error_screenshot.png", full_page=True)
                print("ã‚¨ãƒ©ãƒ¼æ™‚ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜: error_screenshot.png")
            except:
                pass

            return []

        finally:
            # ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã‚‹ï¼ˆ5ç§’å¾Œï¼‰
            print("\n5ç§’å¾Œã«ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã¾ã™...")
            await asyncio.sleep(5)
            await browser.close()
            print("âœ… å®Œäº†\n")


async def scrape_yahoo_jobs():
    """
    Yahoo!ã—ã”ã¨æ¤œç´¢ã‹ã‚‰æ±‚äººæƒ…å ±ã‚’å–å¾—
    ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ã§å‹•ä½œã—ã‚„ã™ã„å®Ÿè£…
    """
    print("\n" + "="*60)
    print("Yahoo!ã—ã”ã¨æ¤œç´¢ - ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°")
    print("="*60 + "\n")

    keyword = "ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼"

    print(f"æ¤œç´¢æ¡ä»¶: {keyword}")
    print("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’èµ·å‹•ä¸­...\n")

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()

        try:
            # Yahoo!ã—ã”ã¨æ¤œç´¢ã«ã‚¢ã‚¯ã‚»ã‚¹
            url = f"https://shigoto.yahoo.co.jp/search/?query={keyword}"
            print(f"ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {url}")

            await page.goto(url, timeout=30000)
            await asyncio.sleep(3)

            print("âœ… ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å®Œäº†\n")

            # æ±‚äººã‚«ãƒ¼ãƒ‰å–å¾—
            job_cards = await page.query_selector_all("article")

            if not job_cards:
                print("âŒ æ±‚äººãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                await page.screenshot(path="error_yahoo.png")
                return []

            print(f"âœ… {len(job_cards)} ä»¶ã®æ±‚äººãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\n")

            jobs = []
            for i, card in enumerate(job_cards[:10], 1):
                try:
                    # ã‚¿ã‚¤ãƒˆãƒ«
                    title_elem = await card.query_selector("h2, h3")
                    title = await title_elem.inner_text() if title_elem else "N/A"

                    # ä¼šç¤¾å
                    company_elem = await card.query_selector(".company, .corp")
                    company = await company_elem.inner_text() if company_elem else "N/A"

                    job = {
                        "ç•ªå·": i,
                        "ã‚¿ã‚¤ãƒˆãƒ«": title.strip(),
                        "ä¼šç¤¾å": company.strip()
                    }
                    jobs.append(job)
                    print(f"{i}. {job['ã‚¿ã‚¤ãƒˆãƒ«'][:50]}...")

                except Exception as e:
                    print(f"âš ï¸  ã‚¨ãƒ©ãƒ¼: {e}")
                    continue

            # ä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"yahoo_jobs_{timestamp}.json"

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(jobs, f, ensure_ascii=False, indent=2)

            print(f"\nğŸ’¾ ä¿å­˜å®Œäº†: {filename}")
            print(f"ğŸ“¸ ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜ä¸­...")
            await page.screenshot(path=f"yahoo_{timestamp}.png")

            return jobs

        except Exception as e:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return []

        finally:
            await asyncio.sleep(5)
            await browser.close()
            print("\nâœ… å®Œäº†")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("\n" + "="*60)
    print("ã‚·ãƒ³ãƒ—ãƒ«æ±‚äººã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼")
    print("="*60)
    print("\né¸æŠã—ã¦ãã ã•ã„:")
    print("1. Indeedï¼ˆæ¨å¥¨ï¼‰")
    print("2. Yahoo!ã—ã”ã¨æ¤œç´¢")
    print("3. ä¸¡æ–¹å®Ÿè¡Œ")
    print("="*60 + "\n")

    choice = input("é¸æŠ (1-3): ").strip()

    if choice == "1":
        asyncio.run(scrape_indeed_simple())
    elif choice == "2":
        asyncio.run(scrape_yahoo_jobs())
    elif choice == "3":
        print("\nã€Indeedã€‘")
        asyncio.run(scrape_indeed_simple())
        print("\nã€Yahoo!ã—ã”ã¨æ¤œç´¢ã€‘")
        asyncio.run(scrape_yahoo_jobs())
    else:
        print("ç„¡åŠ¹ãªé¸æŠã§ã™")


if __name__ == "__main__":
    main()
